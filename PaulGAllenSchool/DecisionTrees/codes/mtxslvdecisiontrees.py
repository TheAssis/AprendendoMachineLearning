# -*- coding: utf-8 -*-
"""MtxslvDecisionTrees.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hY6iUZ4UXQ0qdIRdVs7GIAlurjGgvSG_
"""

# Commented out IPython magic to ensure Python compatibility.
#this is for the purpose of getting MtxslvNode file
# %cd /content/
# %rm -r StudyingMachineLearning/
!git clone https://github.com/mtxslv/StudyingMachineLearning.git
# % cd StudyingMachineLearning/PaulGAllenSchool/DecisionTrees/codes

url_dataset = "https://raw.githubusercontent.com/mtxslv/StudyingMachineLearning/master/PaulGAllenSchool/DecisionTrees/hw1-data/features.txt"
url_labels = "https://raw.githubusercontent.com/mtxslv/StudyingMachineLearning/master/PaulGAllenSchool/DecisionTrees/hw1-data/labels.txt"

import pandas as pd

df_features = pd.read_csv(url_dataset,names=["x-box","y-box", "width","high","onpix","x-bar","y-bar", "x2bar","y2bar","xybar", "x2ybr","xy2br","x-ege","xegvy","y-ege","yegvx"], sep= ' ')
df_labels = pd.read_csv(url_labels,names=["labels"])

lbls = df_labels.to_numpy()
ftrs = df_features.to_numpy()

import numpy as np
from mtxslvnode import * # class is imported by file name (without .py extention)
from mtxslv_math_4_dt import *

class MtxslvDecisionTrees:
  # while using the class, be sure MtxslvNode file is in the folder
  """
  Attributes:
    root: node at the root
    node_quantity: how many nodes there exists
    how_many_classes: how many classes there exists
    attributes_to_test: what attributes can be tested. If True, test it. If False, do not test it.
  """

  def __init__(self):
    self.root = None
    self.node_quantity = 0
    self.how_many_classes = 0

  def fit(self, features, labels, threshold): #method for creating the tree itself
    self._attributes_to_test = [True for x in range(np.shape(features)[1])] # if true, test that attribute during algorithm
                                                                           # if false, do not test that attribute
    self.how_many_classes = len(set(labels[:,0])) # how many classes should I predict?
    
    #print(self.attributes_to_test) for testing, remove later
    #print(self.how_many_classes) for testing, remove later

    self.number = 1 # remove later
    self.root = self._mtxslv_id3(features,labels,threshold)
    #print(self._attributes_to_test.copy())

  def _mtxslv_id3(self, features, labels, threshold):
    current_node = MtxslvNode() # object is instantiated by class name

    if((self.how_many_classes==1)or(not(self._attributes_to_test.count(True)))):
      # if there is only one class, node is a leaf with most probable class; or
      # if all attributes were already tested
      current_node.turn_node_to_leaf(-1,-1,most_common_class(labels))
      return current_node
    else:
      # this is the point in mitchell's id3 algorithm with "otherwise begin" 
      best_classifying_attribute = best_classifier_attribute(features,labels,self._attributes_to_test.copy()) #column of best attribute (0 based)
      possible_attribute_values = set(features[:,best_classifying_attribute]) # set of possible values the best classifying attribute can assume
      self._attributes_to_test[best_classifying_attribute] = False
      for p_a_v in possible_attribute_values:
        features_vi, labels_vi = mtxslv_get_subset(features,labels,best_classifying_attribute,p_a_v)
        current_node.add_branch(best_classifier_attribute,p_a_v, self._mtxslv_id3(features_vi,labels_vi, threshold) ) # i need to put a node in here
    
    return current_node

  
#  def evaluate(): method for using the tree

lista_teste = [True for x in range(np.shape(ftrs)[1])]

lista_features = [[0],[1],[0],[1]]
features_teste = np.concatenate((lista_features,lista_features), axis = 1)
labels_teste = np.array([[1],[1],[0],[1]])
print("features_teste = \n",features_teste)
print("labels_teste = \n",labels_teste)

len(set(lbls[:,0]))

arvore = MtxslvDecisionTrees()

arvore.fit(features_teste, labels_teste,0.05)

arvore.root.child_node[0].child_node[0].is_leaf

arvore.root.child_node[1].is_leaf